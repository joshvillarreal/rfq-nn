{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 11\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m     dvars \u001b[38;5;241m=\u001b[39m [samples[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdvar\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m samples\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[1;32m     13\u001b[0m     objs \u001b[38;5;241m=\u001b[39m [samples[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobj\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m samples\u001b[38;5;241m.\u001b[39mkeys()]\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/json/__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# read in data, configure dataframe\n",
    "target_directory = '../data/full_opt_15KeV'\n",
    "\n",
    "x_dictlist, y_dictlist = [], []\n",
    "\n",
    "for json_file in os.listdir(target_directory):\n",
    "    if json_file[-4:] != 'json':\n",
    "        continue\n",
    "\n",
    "    with open(f'{target_directory}/{json_file}') as f:\n",
    "        samples = json.load(f)['samples']\n",
    "        dvars = [samples[i]['dvar'] for i in samples.keys()]\n",
    "        objs = [samples[i]['obj'] for i in samples.keys()]\n",
    "        \n",
    "        x_dictlist += dvars\n",
    "        y_dictlist += objs\n",
    "        \n",
    "x_df = pd.DataFrame(x_dictlist).apply(pd.to_numeric)\n",
    "y_df = pd.DataFrame(y_dictlist).apply(pd.to_numeric)\n",
    "n_data = x_df.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {\n",
    "    \"DVAR1\": \"Bmax\",\n",
    "    \"DVAR2\": \"mX1\",\n",
    "    \"DVAR3\": \"mX2\",\n",
    "    \"DVAR4\": \"mY1\",\n",
    "    \"DVAR5\": \"mY2\",\n",
    "    \"DVAR6\": \"mtau1\",\n",
    "    \"DVAR7\": \"mtau2\",\n",
    "    \"DVAR8\": \"PhiY1\",\n",
    "    \"DVAR9\": \"PhiY2\",\n",
    "    \"DVAR10\": \"Phitau1\",\n",
    "    \"DVAR11\": \"Phitau2\",\n",
    "    \"DVAR12\": \"mY3ref\",\n",
    "    \"DVAR13\": \"PhiY3ref\",\n",
    "    \"DVAR14\": \"Eref\",\n",
    "}\n",
    "\n",
    "response_dict = {\n",
    "    \"OBJ1\": \"transmission\",\n",
    "    \"OBJ2\": \"output energy\",\n",
    "    \"OBJ3\": \"RFQ length\",\n",
    "    \"OBJ4\": \"longitudinal emittance\",\n",
    "    \"OBJ5\": \"x-emittance\",\n",
    "    \"OBJ6\": \"y-emittance\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(y_df.values[:, 0])\n",
    "# plt.show()\n",
    "\n",
    "# y\n",
    "fig, axs = plt.subplots(2, 3, figsize=(10,6))\n",
    "\n",
    "binwidth = [1.9594, 0.000656, 7.0264, 0.0268638, 0.0019334, 0.002043]\n",
    "\n",
    "for i in range(y_df.shape[1]):\n",
    "    ax = axs.flatten()[i]\n",
    "    ax.hist(y_df.values[:, i], \n",
    "            bins=np.arange(min(y_df.values[:, i]), max(y_df.values[:, i]) + binwidth[i], binwidth[i]),\n",
    "            histtype='step')\n",
    "\n",
    "# Drop data with less than 50% transmission\n",
    "drop_idxs = np.where(y_df.values[:, 0] < 50)\n",
    "\n",
    "x_df.drop(drop_idxs[0], inplace=True)\n",
    "y_df.drop(drop_idxs[0], inplace=True)\n",
    "\n",
    "print(x_df.shape)\n",
    "print(y_df.shape)\n",
    "print(r\"Cut {:.2f}% of the data\".format(100.0 *(n_data - x_df.shape[0])/n_data))\n",
    "\n",
    "for i in range(y_df.shape[1]):\n",
    "    \n",
    "    ax = axs.flatten()[i]\n",
    "    ax.hist(y_df.values[:, i], \n",
    "            bins=np.arange(min(y_df.values[:, i]), max(y_df.values[:, i]) + binwidth[i], binwidth[i]),\n",
    "            histtype='step')\n",
    "    ax.set_title(f'OBJ{i+1}: ' + response_dict[f'OBJ{i+1}'])\n",
    "    \n",
    "    if i==3:\n",
    "        ax.set_yscale(\"log\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(top=0.9)\n",
    "plt.suptitle('Response distributions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.coolwarm\n",
    "\n",
    "# x\n",
    "ticklabels = [''] + [features_dict[f'DVAR{i+1}'] for i in range(x_df.shape[1])]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "corrplot = ax.matshow(x_df.corr(), cmap=cmap)\n",
    "ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.set_xticklabels(ticklabels, rotation=90)\n",
    "ax.yaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.set_yticklabels(ticklabels)\n",
    "cbar = fig.colorbar(corrplot, ax=ax)\n",
    "cbar.minorticks_on()\n",
    "\n",
    "cbar.mappable.set_clim(-1., 1.)\n",
    "\n",
    "fig.suptitle(\"Feature correlations\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y\n",
    "ticklabels = [''] + [response_dict[f'OBJ{i+1}'] for i in range(y_df.shape[1])]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "corrplot = ax.matshow(y_df.corr(), cmap=cmap)\n",
    "ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.set_xticklabels(ticklabels, rotation=90)\n",
    "ax.yaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.set_yticklabels(ticklabels)\n",
    "cbar = fig.colorbar(corrplot, ax=ax)\n",
    "cbar.minorticks_on()\n",
    "\n",
    "cbar.mappable.set_clim(-1., 1.)\n",
    "\n",
    "fig.suptitle(\"Response correlations\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DVARs correlating with OBJ5\n",
    "fig, axs = plt.subplots(4, 4, figsize=(12,8))\n",
    "\n",
    "# Remove transmission < 50%\n",
    "remove_idxs = np.where(y_df.values[:, ] < 0.5)\n",
    "\n",
    "for i in range(x_df.shape[1]):\n",
    "    ax = axs.flatten()[i]\n",
    "    ax.scatter(y_df.values[:, 1], x_df.values[:, i], s=1)\n",
    "    ax.set_xlabel(f'OBJ2')\n",
    "    ax.set_ylabel(f'DVAR{i+1}: ' + features_dict[f'DVAR{i+1}'])\n",
    "    corr, _ = pearsonr(y_df.values[:, 4], x_df.values[:, i])\n",
    "    print(f'DVAR{i+1} and OBJ2', 'Pearsons correlation: %.3f' % corr)\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(top=0.9)\n",
    "plt.suptitle('OBJ2 Scatter Plots')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  x and y\n",
    "xy_df = pd.concat([x_df, y_df], axis=1)\n",
    "print(xy_df.shape)\n",
    "\n",
    "ticklabels = [''] + [features_dict[f'DVAR{i+1}'] for i in range(x_df.shape[1])]\\\n",
    "                  + [response_dict[f'OBJ{i+1}'] for i in range(y_df.shape[1])]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "corrplot = ax.matshow(xy_df.corr(), cmap=cmap)\n",
    "ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.set_xticklabels(ticklabels, rotation=90)\n",
    "ax.yaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.set_yticklabels(ticklabels)\n",
    "cbar = fig.colorbar(corrplot, ax=ax)\n",
    "cbar.minorticks_on()\n",
    "plt.axvline(13.5)\n",
    "plt.axhline(13.5)\n",
    "\n",
    "cbar.mappable.set_clim(-1., 1.)\n",
    "\n",
    "fig.suptitle(\"Response correlations\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions and rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x\n",
    "fig, axs = plt.subplots(4, 4, figsize=(12,8))\n",
    "\n",
    "for i in range(x_df.shape[1]):\n",
    "    ax = axs.flatten()[i]\n",
    "    ax.hist(x_df.values[:, i], bins=50)\n",
    "    ax.set_title(f'DVAR{i+1}: ' + features_dict[f'DVAR{i+1}'])\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(top=0.9)\n",
    "plt.suptitle('Feature distributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y\n",
    "fig, axs = plt.subplots(2, 3, figsize=(10,6))\n",
    "\n",
    "for i in range(y_df.shape[1]):\n",
    "    ax = axs.flatten()[i]\n",
    "    ax.hist(y_df.values[:, i], bins=50)\n",
    "    ax.set_title(f'OBJ{i+1}: ' + response_dict[f'OBJ{i+1}'])\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(top=0.9)\n",
    "plt.suptitle('Response distributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\texttt{DVAR3}$ is determined in the following way. For some buffer $\\eta_3 = 10.$:\n",
    "\n",
    "$$ \\texttt{DVAR2} \\sim \\textrm{Uniform}(L_2, U_2) $$\n",
    "$$ \\texttt{DVAR3} \\sim \\textrm{Uniform}(\\texttt{DVAR2} + \\eta_3, U_3)$$\n",
    "\n",
    "Which means that we can introduce \n",
    "$$\\texttt{DVAR3}' \\equiv \\frac{\\texttt{DVAR3} - (\\texttt{DVAR2} + \\eta_3)}{U_3 - (\\texttt{DVAR2} + \\eta_3)} \\sim \\textrm{Uniform} (0, 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prime_dvar_values(to_transform, dynamic_lower_bound, strict_upper_bound):\n",
    "    return (to_transform - dynamic_lower_bound) / (strict_upper_bound - dynamic_lower_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dvar3\n",
    "max_dvar_3 = 160\n",
    "eta_3 = 10.\n",
    "dvar_3_prime = get_prime_dvar_values(x_df['DVAR3'], eta_3 + x_df['DVAR2'], max_dvar_3)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axs[0].hist(x_df['DVAR3'], bins=50)\n",
    "axs[0].set_title('DVAR3')\n",
    "\n",
    "axs[1].hist(dvar_3_prime, bins=50)\n",
    "axs[1].set_title('DVAR3\\'')\n",
    "\n",
    "plt.savefig('dvar3_and_prime_hist.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the $\\texttt{DVAR4} < \\texttt{DVAR5} < \\texttt{DVAR12}$ relationship means these are correlated. For $\\eta_5 = 0.05$ and $\\eta_{12} = 0.05$:\n",
    "\n",
    "$$ \\texttt{DVAR4} \\sim \\textrm{Uniform} (L_4, U_4) $$\n",
    "$$ \\texttt{DVAR5} \\sim \\textrm{Uniform} (\\texttt{DVAR4} + \\eta_5, U_5)$$\n",
    "$$ \\texttt{DVAR12} \\sim \\textrm{Uniform} (\\texttt{DVAR12} + \\eta_{12}, U_{12})$$\n",
    "\n",
    "And for some buffers $\\eta_9 = 2.5$ and $\\eta_{13} = 2.5$:\n",
    "\n",
    "$$ \\texttt{DVAR8} \\sim \\textrm{Uniform}(L_8, U_8) $$\n",
    "$$ \\texttt{DVAR9} \\sim \\textrm{Uniform}(\\texttt{DVAR8} + \\eta_9, U_9)$$\n",
    "$$ \\texttt{DVAR13} \\sim \\textrm{Uniform}(\\texttt{DVAR9} + \\eta_{13}, U_{13})$$\n",
    "\n",
    "Thus, for $\\texttt{DVAR5}, \\texttt{DVAR9}, \\texttt{DVAR12}, \\texttt{DVAR13}$ we can transform to the primed definitions using the same procedure outlined above. Importantly, note that the primed design variables are decorrelated from the unprimed design variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dvar5\n",
    "max_dvar_5 = 1.85\n",
    "eta_5 = 0.05\n",
    "dvar_5_prime = get_prime_dvar_values(x_df['DVAR5'], x_df['DVAR4'] + eta_5, max_dvar_5)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axs[0].hist(x_df['DVAR5'], bins=50)\n",
    "axs[0].set_title('DVAR5')\n",
    "\n",
    "axs[1].hist(dvar_5_prime, bins=50)\n",
    "axs[1].set_title('DVAR5\\'')\n",
    "plt.show()\n",
    "\n",
    "# transform dvar12\n",
    "max_dvar_12 = 2.0\n",
    "eta_12 = 0.05\n",
    "dvar_12_prime = get_prime_dvar_values(x_df['DVAR12'], x_df['DVAR5'] + eta_12, max_dvar_12)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axs[0].hist(x_df['DVAR12'], bins=50)\n",
    "axs[0].set_title('DVAR12')\n",
    "\n",
    "axs[1].hist(dvar_12_prime, bins=50)\n",
    "axs[1].set_title('DVAR12\\'')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dvar9\n",
    "max_dvar_9 = -25.\n",
    "eta_9 = 2.5\n",
    "dvar_9_prime = get_prime_dvar_values(x_df['DVAR9'], x_df['DVAR8'] + eta_9, max_dvar_9)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "axs[0].hist(x_df['DVAR9'], bins=50)\n",
    "axs[0].set_title('DVAR9')\n",
    "\n",
    "axs[1].hist(dvar_9_prime, bins=50)\n",
    "axs[1].set_title('DVAR9\\'')\n",
    "plt.show()\n",
    "\n",
    "# transform dvar13\n",
    "max_dvar_13 = -20.\n",
    "eta_13 = 2.5\n",
    "dvar_13_prime = get_prime_dvar_values(x_df['DVAR13'], x_df['DVAR9'] + eta_13, max_dvar_13)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axs[0].hist(x_df['DVAR13'], bins=50)\n",
    "axs[0].set_title('DVAR13')\n",
    "\n",
    "axs[1].hist(dvar_13_prime, bins=50)\n",
    "axs[1].set_title('DVAR13\\'')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfomred data correlation plot\n",
    "cmap = cm.coolwarm\n",
    "\n",
    "x_df_2 = x_df.copy()\n",
    "x_df_2['DVAR3'] = dvar_3_prime\n",
    "x_df_2['DVAR5'] = dvar_5_prime\n",
    "x_df_2['DVAR9'] = dvar_9_prime\n",
    "x_df_2['DVAR12'] = dvar_12_prime\n",
    "x_df_2['DVAR13'] = dvar_13_prime\n",
    "\n",
    "# x\n",
    "ticklabels = [''] + [features_dict[f'DVAR{i+1}'] for i in range(x_df_2.shape[1])]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "corrplot = ax.matshow(x_df_2.corr(), cmap=cmap)\n",
    "ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.set_xticklabels(ticklabels, rotation=90)\n",
    "ax.yaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.set_yticklabels(ticklabels)\n",
    "cbar = fig.colorbar(corrplot, ax=ax)\n",
    "cbar.minorticks_on()\n",
    "\n",
    "cbar.mappable.set_clim(-1., 1.)\n",
    "\n",
    "fig.suptitle(\"Feature correlations -- transformed data\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 6))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i == 0:\n",
    "        im = ax.matshow(x_df.corr(), cmap=cmap, vmin=-1., vmax=1.)\n",
    "        ax.set_title('Raw data')\n",
    "    else:\n",
    "        im = ax.matshow(x_df_2.corr(), cmap=cmap, vmin=-1., vmax=1.)\n",
    "        ax.set_title('Decorrelated data')\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "    ax.set_xticklabels(ticklabels, rotation=90)\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(1))\n",
    "    ax.set_yticklabels(ticklabels)\n",
    "    ax.tick_params(axis=\"x\", bottom=True, top=False, labelbottom=True, labeltop=False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(right=0.87)\n",
    "cbar_ax = fig.add_axes([0.90, 0.15, 0.02, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "plt.savefig('correlationmatrix.png', dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Our variables are decorrelated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothness of the feature / response space?\n",
    "\n",
    "My thinking here is that maybe the reason that the neural networks haven't been doing a good job understanding the relationship between the RFQ design variabels and objectives is because there could be non-smoothness in the function that could lend the relationship difficult to predict.\n",
    "\n",
    "The purpose of this analysis is to test the hypothesis of local smoothness; that is, small changes in the design variables should be accompanied by small changes in the objectives.\n",
    "\n",
    "To this end, I compute the Euclidean distance between two non-equal vectors in the feature space, and compare this value with the corresponding Euclidean distance between the two data entry's objective values. The data that I use for this is scaled to allow for easy interperetability between any two feature vectors. If the relationship is more jagged than we expect, which could give difficult to the neural network, then small changes in the feature space would be associated with lare changes in the response space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min max scale features and response\n",
    "x_scaled_df = pd.DataFrame(MinMaxScaler().fit_transform(x_df_2), columns=x_df_2.columns)\n",
    "y_scaled_df = pd.DataFrame(MinMaxScaler().fit_transform(y_df), columns=y_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_range = [0.1, 0.9]\n",
    "subsample_mask = ((x_scaled_df >= subsample_range[0]) & (x_scaled_df <= subsample_range[1])).all(axis=1)\n",
    "\n",
    "x_scaled_subsample_df = x_scaled_df[subsample_mask]; y_scaled_subsample_df = y_scaled_df[subsample_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_distances = cdist(x_scaled_subsample_df, x_scaled_subsample_df, \"euclid\")\n",
    "y_distances = cdist(y_scaled_subsample_df, y_scaled_subsample_df, \"euclid\")\n",
    "\n",
    "# drop diagonal elements and flatten\n",
    "def drop_diags_and_flatten(A):\n",
    "    return A[~np.eye(A.shape[0],dtype=bool)]\n",
    "\n",
    "x_distances = drop_diags_and_flatten(x_distances)\n",
    "y_distances = drop_diags_and_flatten(y_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7,6))\n",
    "\n",
    "hist = ax.hist2d(x_distances, y_distances, norm=mpl.colors.LogNorm(), bins=100)\n",
    "ax.set_xlabel('Euclidean feature distance')\n",
    "ax.set_ylabel('Euclidean response distances')\n",
    "fig.colorbar(hist[3], ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, note the limitations of the data. The features that I used are normalized so that they are all uncorrelated and look like a Uniform distribution. There are 14 design variables that are treated as features in this analysis. Thus, data points that are close together in the feature space are rare. For instance, the probability of any one feature vector to have all component values within some range of width $0.1$ is $0.1^{14} = 10^{-14}$.\n",
    "\n",
    "That said, the plot that I show above demonstrates that for any two data points, the Euclidean distance of their objective values is somewhat bounded by the Euclidean distance of their response values. Is this true for all responses separately?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
